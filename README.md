## Explaining file attached to the repo

1.** Web_Scrapper (App)** - In the folder we have added the Python code and app code we created using Streamlit, there are two main files one is the class we created with the name 'TrustPilotScraper' and then we created the code in it to scrapped the desired organization from "trust-pilot" and several pages you want to scrap. The other file App.py is the important file to initiate the app in the streamlit local host. 

2. **Data_Scrapped** - This is the CSV file in which the data collected from the app has been stored for further analysis. This file contains data from two companies "One Call Insurance" and "ROC". The CSV File contains multiple columns which the app created an extract from the "Trust_pilot"

3. **Project-After_Web_Scrapping**- This file contains the data wrangling and analysis of all data_scrapped throughout the phase and follows the path as described in the document to guide the project.


