## Explaininf file attached to the repo

1.** Web_Scrapper (App)** - In the folder we have added the python code and app code we created using streamlit, in these there are two main files one is the class we created with the name of
'TrustPilotScraper' then we created the code in it to scrapped the desired organisation from "trust-pilot" and number of pages you want to scrap. The other file App.py is the 
important file to initiate the app in streamlit local host. 

2. **Data_Scrapped** - This is the CSV file in which the data collected from app has been stored for further analysis. This file contain data of two companies "One Call Insurance" and
"ROC". The CSV File contain multiple column which the app created can extract from the "Trust_pilot"

3. **Project-After_Web_Scrapping**- This file contain the data wrangling and analysis of all data_scrapped through out the phase and follows the path as described in the document 
to guide the project.


